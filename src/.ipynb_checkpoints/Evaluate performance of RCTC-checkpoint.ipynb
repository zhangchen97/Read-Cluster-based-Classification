{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pre_Sen(lst_true,lst_pre): \n",
    "    numOfAmbiguousTrue=0;  ##代表在某个level上，真实值的taxID没找到，赋值为-1\n",
    "    numOfAmbiguousPredictionTrue=0  ##在某个level上，真实值和预测值的taxID都没找到，赋值为-1\n",
    "    numOfUnClassified=0   ##没有分类的数量\n",
    "    numOfCorrectAssign=0;\n",
    "    numOfAssign=0;\n",
    "    numOfAll=len(lst_true);\n",
    "    for i in range(len(lst_true)):\n",
    "        if(lst_true[i]==-1):\n",
    "            numOfAmbiguousTrue=numOfAmbiguousTrue+1\n",
    "        if(lst_true[i]==-1 and lst_pre[i]==-1):##代表没有答案\n",
    "            numOfAmbiguousPredictionTrue=numOfAmbiguousPredictionTrue+1\n",
    "            continue\n",
    "        if(lst_pre[i]==0):\n",
    "            numOfUnClassified=numOfUnClassified+1\n",
    "        else:\n",
    "            numOfAssign=numOfAssign+1;\n",
    "            if(lst_pre[i]==lst_true[i]):\n",
    "                numOfCorrectAssign=numOfCorrectAssign+1\n",
    "    print(\"numOfAmbiguousTrue: \"+str(numOfAmbiguousTrue))\n",
    "    print(\"numOfAmbiguousPredictionTrue: \"+str(numOfAmbiguousPredictionTrue))\n",
    "    print(\"numOfUnClassified: \"+str(numOfUnClassified))\n",
    "    print(\"numOfCorrectAssign: \"+str(numOfCorrectAssign))\n",
    "    print(\"numOfAssign: \"+str(numOfAssign))\n",
    "    print(\"numOfAll: \"+str(numOfAll))\n",
    "    Precision=numOfCorrectAssign/numOfAssign\n",
    "    Sensitivity=numOfCorrectAssign/numOfAll\n",
    "    print(\"Precision: \"+str(Precision))\n",
    "    print(\"Sensitivity: \"+str(Sensitivity))\n",
    "    F1= 2*Precision*Sensitivity/(Precision+Sensitivity)\n",
    "    print(\"F1 Measure: \"+str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1：将数据集里分类正确的过滤出来。\n",
    "def compute_MAPE(TrueLevelcounter,Predict):\n",
    "    ##计算MAPE\n",
    "    n=len(TrueLevelcounter)\n",
    "    result=0.0;\n",
    "    for k,v in TrueLevelcounter.items():\n",
    "        R_true=v\n",
    "        R_est=Predict[k]\n",
    "        result=result+abs(R_true-R_est)/R_true\n",
    "        #print(\"R_true:\"+str(R_true)+\"   R_est:\"+str(R_est)+\" Result:\"+str(result))\n",
    "    return result/n*100\n",
    "\n",
    "def Compute_Abundance(TrueLevel,TargetLevel):\n",
    "    ##统计答案的species的数量\n",
    "    TrueLevelcounter=dict(Counter(TrueLevel))\n",
    "    if( -1 in TrueLevelcounter):\n",
    "        del TrueLevelcounter[-1]\n",
    "    if( 0 in TrueLevelcounter):\n",
    "        del TrueLevelcounter[0]\n",
    "    keys_true=set(TrueLevelcounter.keys())\n",
    "    #print(TrueLevelcounter)\n",
    "    \n",
    "    ##Target\n",
    "    TargetLevelcounter=dict(Counter(TargetLevel))\n",
    "    #print(TargetLevelcounter)\n",
    "  \n",
    "    for key in keys_true:\n",
    "        if key not in TargetLevelcounter:\n",
    "            TargetLevelcounter[key]=0\n",
    "    ##计算\n",
    "    MAPE=compute_MAPE(TrueLevelcounter,TargetLevelcounter)\n",
    "    print(\"MAPE: \"+str(MAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Species_ACC(path):\n",
    "    df=pd.read_csv(path)\n",
    "    df.columns=['clusterid','readname','clark_clu_species','kra_clu_species','true_taxid','kra_id','clark_taxid','true_species','kra_species','clark_species']\n",
    "    new_df5=df.set_index('readname')\n",
    "    print(new_df5.head())\n",
    "    print(new_df5.shape)\n",
    "#     lst_true=list(new_df5['true_species'])\n",
    "#     lst_kra=list(new_df5['kra_species'])\n",
    "#     lst_clark=list(new_df5['clark_species'])\n",
    "#     lst_kra_clu=list(new_df5['kra_clu_species'])\n",
    "#     lst_clark_clu=list(new_df5['clark_clu_species'])\n",
    "#     print(\"============================Kraken2 Speices Level Result Show==================================\")\n",
    "#     Pre_Sen(lst_true,lst_kra)\n",
    "#     Compute_Abundance(lst_true,lst_kra)\n",
    "#     print(\"=======================Kraken2 LocalClustering Species Level Result Show============================ \")\n",
    "#     Pre_Sen(lst_true,lst_kra_clu)\n",
    "#     Compute_Abundance(lst_true,lst_kra_clu)\n",
    "#     print(\"============================Clark Speices Level Result Show==================================\")\n",
    "#     Pre_Sen(lst_true,lst_clark)\n",
    "#     Compute_Abundance(lst_true,lst_clark)\n",
    "#     print(\"=======================Clark LocalClustering Species Level Result Show============================ \")\n",
    "#     Pre_Sen(lst_true,lst_clark_clu)\n",
    "#     Compute_Abundance(lst_true,lst_clark_clu)\n",
    "    return new_df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Genus_ACC(path):\n",
    "    df=pd.read_csv(path)\n",
    "    df.columns=['clusterid','readname','clark_clu_genus','kra_clu_genus','true_taxid','kra_id','clark_taxid','true_genus','kra_genus','clark_genus']\n",
    "    new_df4=df.set_index('readname')\n",
    "    print(new_df4.head())\n",
    "    print(new_df4.shape)\n",
    "    lst_true=list(new_df4['true_genus'])\n",
    "    lst_kra=list(new_df4['kra_genus'])\n",
    "    lst_clark=list(new_df4['clark_genus'])\n",
    "    lst_kra_clu=list(new_df4['kra_clu_genus'])\n",
    "    lst_clark_clu=list(new_df4['clark_clu_genus'])\n",
    "    print(\"============================Kraken2 Genus Level Result Show==================================\")\n",
    "    Pre_Sen(lst_true,lst_kra)\n",
    "    Compute_Abundance(lst_true,lst_kra)\n",
    "    print(\"=======================Kraken2 LocalClustering Genus Level Result Show============================ \")\n",
    "    Pre_Sen(lst_true,lst_kra_clu)\n",
    "    Compute_Abundance(lst_true,lst_kra_clu)\n",
    "    print(\"============================Clark Genus Level Result Show==================================\")\n",
    "    Pre_Sen(lst_true,lst_clark)\n",
    "    Compute_Abundance(lst_true,lst_clark)\n",
    "    print(\"=======================Clark LocalClustering Genus Level Result Show============================ \")\n",
    "    Pre_Sen(lst_true,lst_clark_clu)\n",
    "    Compute_Abundance(lst_true,lst_clark_clu)\n",
    "    return new_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "from matplotlib_venn import venn3\n",
    "def AnalysisSpecies(df,level):\n",
    "    ##统计species的数量\n",
    "    TrueSpcies=set(list(df[\"true_\"+level]))\n",
    "    CluSpecies=set(list(df[\"clu_\"+level]))\n",
    "    LstKraSpecies=list(df[\"kra_\"+level])\n",
    "    DictKraSpecies=dict(Counter(LstKraSpecies))\n",
    "    KraSpecies=set(DictKraSpecies.keys())\n",
    "#     KraSpecies=set()\n",
    "#     for key,val in DictKraSpecies.items():\n",
    "#         if(val>10):\n",
    "#             KraSpecies.add(key)\n",
    "    ##把kraken2的结果，取taxid 5条以上以上的分析\n",
    "    numOfTrueSpecies=len(TrueSpcies) #数据集里真实species数量\n",
    "    numOfCluSpecies=len(CluSpecies)  #数量\n",
    "    numOfKraSpecies=len(KraSpecies)  #数量\n",
    "    print(\"numOfTrueSpecies: \"+str(numOfTrueSpecies))\n",
    "    print(\"numOfCluSpecies: \"+str(numOfCluSpecies))\n",
    "    print(\"numOfKraSpecies: \"+str(numOfKraSpecies))\n",
    "    ##画venn图\n",
    "    venn3(subsets=[TrueSpcies,CluSpecies,KraSpecies],set_labels=('True_'+level,'Cluster_'+level,'Kraken_'+level),set_colors=('r','b','g'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Result of Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_Species_ACC(\"allReads_dir/CAMI2_mouse_allreads_tax_species_V3_0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_Genus_ACC(\"allReads_dir/CAMI2_mouse_allreads_tax_genus_V3_0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze purity and completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as numpy\n",
    "import pandas as pd \n",
    "from imp import reload\n",
    "from sklearn import  metrics\n",
    "\n",
    "import sys\n",
    "if not \"/home/ubuntu/\" in sys.path:\n",
    "    sys.path.append(\"/home/ubuntu/\")\n",
    "if not 'function' in sys.modules:\n",
    "    function = __import__('function')\n",
    "else:\n",
    "    eval('import function')\n",
    "    function = eval('reload(function)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLocal=new_species_df[['readname','clusterid']]\n",
    "dfLocal.columns=['node','cluster']\n",
    "ret,dfLocal=function.analysize(label,dfLocal)\n",
    "print(dfLocal.head())\n",
    "print(dfLocal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGlobal=new_species_df[['readname','kra_clu_species']]\n",
    "dfGlobal.columns=['node','cluster']\n",
    "ret,dfGlobal=function.analysize(label,dfGlobal)\n",
    "print(dfGlobal.head())\n",
    "print(dfGlobal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local_purity=dfLocal.groupby(['cid'])[['c_count','purification']].max().reset_index().sort_values('c_count',ascending=False)\n",
    "df_local_completeness=dfLocal.groupby(['rname'])[['r_count','completeness']].max().reset_index().sort_values('r_count',ascending=False)\n",
    "df_global_purity=dfGlobal.groupby(['cid'])[['c_count','purification']].max().reset_index().sort_values('c_count',ascending=False)\n",
    "df_global_completeness=dfGlobal.groupby(['rname'])[['r_count','completeness']].max().reset_index().sort_values('r_count',ascending=False)\n",
    "merge=[df_local_completeness['completeness']*100,df_global_completeness['completeness']*100,\\\n",
    "      df_local_purity['purification']*100,df_global_purity['purification']*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(values):\n",
    "    fake=list(sort(values))\n",
    "    SUM=float(reduce(lambda x,y:x+y,fake))\n",
    "    j=0\n",
    "    thd=np.power(10,np.linspace(1,10,60))\n",
    "   # thd=[100,1000,10000,100000,1000000,10000000]\n",
    "    pcd = [[0] * len(fake) for i in range(len(thd))]\n",
    "    alist=[]\n",
    "    for i in np.arange(len(fake)):\n",
    "        if thd[j]<=fake[i]<thd[j+1]:\n",
    "            pcd[j].append(fake[i])\n",
    "        else:\n",
    "            print(j)\n",
    "            print(fake[i])\n",
    "            j=j+1\n",
    "            pcd[j].append(fake[i])\n",
    "    for j in np.arange(len(thd)):\n",
    "        alist.append(sum(pcd[j])/SUM*100)\n",
    "    return alist\n",
    "def add_labels(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width() / 2, height, height, ha='center', va='bottom')\n",
    "        rect.set_edgecolor('white')\n",
    "##Local vs Global\n",
    "#fname=\"Local vs Global\"\n",
    "def plt_figure1(merge,tool):\n",
    "    #fname=\"Based-Cluster vs Global\"\n",
    "    bins=50\n",
    "    alpha=1\n",
    "    localcolor='darkgray'\n",
    "    globalcolor='dimgray'\n",
    "    fig1 = plt.figure(num=1, figsize=(12, 12), dpi=600)\n",
    "    plt.subplots_adjust( wspace=.1, hspace=.1 )\n",
    "    if 2:\n",
    "        ax1=plt.subplot(3,1,2)\n",
    "        medianprops = dict(linestyle='-', linewidth=3, color='black')\n",
    "        sns.violinplot(data=merge,width=0.9,inner=None,color=\"w\", scale='width')\n",
    "        bplot=boxplot(merge,showfliers=False,positions=[0,1,2,3],patch_artist = True,widths=0.10,medianprops =medianprops)\n",
    "\n",
    "       # ax1.set_title('Performance comparison',fontsize=16)\n",
    "        ax1.set_xlabel(\"cluster purity and completeness distribution\",fontsize=14)  \n",
    "        colors = [localcolor, globalcolor, localcolor, globalcolor,localcolor, globalcolor]#颜色填充\n",
    "        for patch, color in zip(bplot['boxes'], colors):patch.set_facecolor(color)      \n",
    "        ax1.tick_params(labelsize=12)\n",
    "        plt.setp(ax1, xticks=[0.5,2.5,4.5],xticklabels=['completeness','purity','       '])\n",
    "        ax1.legend([bplot[\"boxes\"][0], bplot[\"boxes\"][1]], [ 'Local Clustering','Based-Cluster '+tool],bbox_to_anchor=(0.5, 1.0),fontsize=14)   #图例 \n",
    "    plt.tight_layout();\n",
    "    #fig1.savefig(fname + '.pdf', format='pdf') \n",
    "    plt.show()\n",
    "def plt_figure2(merge,df_local_purity,df_global_purity,tool):\n",
    "    fname=\"Based-Cluster vs Global\"\n",
    "    bins=50\n",
    "    alpha=1\n",
    "    localcolor='darkgray'\n",
    "    globalcolor='dimgray'\n",
    "    fig1 = plt.figure(num=1, figsize=(12, 12), dpi=600)\n",
    "    plt.subplots_adjust( wspace=.1, hspace=.1 )\n",
    "    if 1:\n",
    "        ax2=plt.subplot(3,1,1)\n",
    "       # ax2.set_title('Cluster size comparison',fontsize=16)\n",
    "        ax2.set_ylabel(\"% of clusters\",fontsize=14) \n",
    "        ax2.set_xlabel(\"cluster size(log10)\",fontsize=14)  \n",
    "        values=percent(df_local_purity['c_count'].values)\n",
    "        local= ax2.bar(np.arange(len(values)),values,color=localcolor,alpha=alpha,label='Based-Cluster '+tool) \n",
    "\n",
    "        values=percent(df_global_purity['c_count'].values)\n",
    "        Global= ax2.bar(np.arange(len(values)),values,color=globalcolor,alpha=alpha,label='Global')\n",
    "        plt.legend(loc='best',fontsize=14)\n",
    "        scale_ls = np.arange(len(values))\n",
    "        index_ls = [' ',' ',' ',\n",
    "                   '2',' ',' ',' ',' ',' ',' ',' ',' ',' ',\n",
    "                   '3',' ',' ',' ',' ',' ',' ',' ',' ',' ',\n",
    "                   '4',' ',' ',' ',' ',' ',' ',' ',' ',' ',\n",
    "                   '5',' ',' ',' ',' ',' ',' ',' ',' ',' ',\n",
    "                   '6',' ',' ',' ',' ',' ',' ',' ',' ',' ',\n",
    "                   '7']\n",
    "        plt.xticks(scale_ls,index_ls)  ## 可以设置坐标字\n",
    "    plt.tight_layout();\n",
    "    fig1.savefig(fname + '.pdf', format='pdf') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGlobal=new_species_df[['readname','clark_clu_species']]\n",
    "dfGlobal.columns=['node','cluster']\n",
    "ret,dfGlobal=function.analysize(label,dfGlobal)\n",
    "print(dfGlobal.head())\n",
    "print(dfGlobal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local_purity=dfLocal.groupby(['cid'])[['c_count','purification']].max().reset_index().sort_values('c_count',ascending=False)\n",
    "df_local_completeness=dfLocal.groupby(['rname'])[['r_count','completeness']].max().reset_index().sort_values('r_count',ascending=False)\n",
    "df_global_purity=dfGlobal.groupby(['cid'])[['c_count','purification']].max().reset_index().sort_values('c_count',ascending=False)\n",
    "df_global_completeness=dfGlobal.groupby(['rname'])[['r_count','completeness']].max().reset_index().sort_values('r_count',ascending=False)\n",
    "merge=[df_local_completeness['completeness']*100,df_global_completeness['completeness']*100,\\\n",
    "      df_local_purity['purification']*100,df_global_purity['purification']*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt_figure1(merge,\"Clark\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
